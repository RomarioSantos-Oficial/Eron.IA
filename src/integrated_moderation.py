"""
IntegraÃ§Ã£o de ModeraÃ§Ã£o Seletiva com Sistema Existente
======================================================

Integra a moderaÃ§Ã£o seletiva com o sistema de personalizaÃ§Ã£o existente,
permitindo que usuÃ¡rios adultos tenham personalizaÃ§Ã£o sem restriÃ§Ãµes.

Autor: Eron.IA System
"""

import sys
import os
from pathlib import Path

# Adicionar diretÃ³rio pai para imports
sys.path.append(str(Path(__file__).parent.parent))

try:
    from src.selective_moderation import (
        get_selective_config, 
        check_personalization_moderation,
        ModerationContext,
        PersonalizationModerator
    )
    from src.adult_content_moderator import AdultContentModerator
    from src.flexible_moderation import FlexibleModerationConfig
except ImportError as e:
    print(f"âš ï¸ Aviso: Alguns mÃ³dulos nÃ£o disponÃ­veis - {e}")

class IntegratedModerationSystem:
    """Sistema integrado que aplica moderaÃ§Ã£o seletiva baseada no contexto"""
    
    def __init__(self):
        self.selective_config = get_selective_config()
        self.personalization_moderator = PersonalizationModerator()
        
        # Sistemas de fallback
        try:
            self.adult_moderator = AdultContentModerator()
        except:
            self.adult_moderator = None
            
        print("ğŸ¯ Sistema de moderaÃ§Ã£o seletiva inicializado")
        print("   â€¢ PersonalizaÃ§Ã£o: Livre para adultos")
        print("   â€¢ Outros contextos: ModeraÃ§Ã£o normal")
    
    def analyze_content(self, content: str, context: str, user_id: str = None, user_is_adult: bool = False) -> dict:
        """
        AnÃ¡lise de conteÃºdo com moderaÃ§Ã£o seletiva baseada no contexto
        
        Args:
            content: Texto a ser analisado
            context: Contexto ('personalization', 'general_chat', etc.)
            user_id: ID do usuÃ¡rio
            user_is_adult: Se o usuÃ¡rio Ã© adulto verificado
        
        Returns:
            Dict com resultado da anÃ¡lise
        """
        
        # Verificar se Ã© personalizaÃ§Ã£o
        if context == 'personalization':
            return self._analyze_personalization_content(content, user_id, user_is_adult)
        
        # Para outros contextos, usar moderaÃ§Ã£o normal
        return self._analyze_general_content(content, context, user_id)
    
    def _analyze_personalization_content(self, content: str, user_id: str, user_is_adult: bool) -> dict:
        """AnÃ¡lise especÃ­fica para personalizaÃ§Ã£o"""
        
        # Se usuÃ¡rio Ã© adulto, permitir praticamente tudo
        if user_is_adult:
            return {
                'severity': 'clean',
                'action': 'allow',
                'reason': 'PersonalizaÃ§Ã£o livre para usuÃ¡rio adulto',
                'confidence': 0.0,
                'flagged_words': [],
                'context': 'personalization',
                'moderation_bypassed': True,
                'user_is_adult': True,
                'timestamp': self._get_timestamp()
            }
        
        # Para menores, verificar apenas spam/assÃ©dio bÃ¡sico
        result = self.personalization_moderator.should_allow_personalization_content(
            user_id, content, user_is_adult
        )
        
        return {
            'severity': 'clean' if result['allowed'] else 'mild',
            'action': result['action'],
            'reason': result['reason'],
            'confidence': 0.1 if not result['allowed'] else 0.0,
            'flagged_words': [],
            'context': 'personalization',
            'moderation_bypassed': False,
            'user_is_adult': False,
            'timestamp': self._get_timestamp()
        }
    
    def _analyze_general_content(self, content: str, context: str, user_id: str) -> dict:
        """AnÃ¡lise para contextos gerais (com moderaÃ§Ã£o normal)"""
        
        # Se temos o moderador adulto disponÃ­vel, usar ele
        if self.adult_moderator:
            try:
                result = self.adult_moderator.analyze_content(content, user_id)
                result['context'] = context
                result['moderation_bypassed'] = False
                return result
            except Exception as e:
                print(f"Erro ao usar moderador adulto: {e}")
        
        # Fallback: anÃ¡lise bÃ¡sica
        return {
            'severity': 'clean',
            'action': 'allow',
            'reason': 'AnÃ¡lise bÃ¡sica - conteÃºdo permitido',
            'confidence': 0.0,
            'flagged_words': [],
            'context': context,
            'moderation_bypassed': False,
            'timestamp': self._get_timestamp()
        }
    
    def _get_timestamp(self):
        """Timestamp atual"""
        from datetime import datetime
        return datetime.now().isoformat()
    
    def is_user_adult(self, user_id: str) -> bool:
        """
        Verifica se usuÃ¡rio Ã© adulto (implementar baseado no seu sistema)
        Por enquanto, retorna False como padrÃ£o seguro
        """
        try:
            # Aqui vocÃª pode integrar com seu sistema de verificaÃ§Ã£o de idade
            # Por exemplo, verificando no banco de dados do usuÃ¡rio
            from core.user_profile_db import UserProfileDB
            profile_db = UserProfileDB()
            profile = profile_db.get_user_profile(user_id)
            
            if profile and profile.get('age'):
                age = int(profile.get('age', 0))
                return age >= 18
            
            # Verificar se tem configuraÃ§Ã£o de adulto habilitada
            return profile.get('adult_mode_enabled', False) if profile else False
            
        except Exception as e:
            print(f"Erro ao verificar idade: {e}")
            return False
    
    def get_personalization_guidelines(self, user_is_adult: bool) -> str:
        """Retorna diretrizes de personalizaÃ§Ã£o baseadas na idade"""
        
        if user_is_adult:
            return """
ğŸ­ **PERSONALIZAÃ‡ÃƒO LIVRE PARA ADULTOS**

VocÃª pode personalizar livremente:
â€¢ Linguagem explÃ­cita e adulta
â€¢ Temas sexuais e romÃ¢nticos
â€¢ Personalidade provocativa ou sedutora
â€¢ ReferÃªncias adultas sem restriÃ§Ãµes
â€¢ Conversas explÃ­citas sobre preferÃªncias

âš ï¸ **Nota:** Esta liberdade se aplica apenas Ã  configuraÃ§Ã£o da personalizaÃ§Ã£o.
Os chats normais ainda seguem as regras de moderaÃ§Ã£o padrÃ£o.
"""
        else:
            return """
ğŸ¨ **PERSONALIZAÃ‡ÃƒO FAMILIAR**

VocÃª pode personalizar:
â€¢ Nome e personalidade do bot
â€¢ Estilo de conversa apropriado
â€¢ Interesses e hobbies
â€¢ Linguagem respeitosa
â€¢ Temas adequados para todas as idades

ğŸ’¡ Mantenha um ambiente respeitoso e apropriado.
"""
    
    def get_system_status(self) -> str:
        """Retorna status do sistema"""
        return self.selective_config.get_status_summary()


# InstÃ¢ncia global do sistema integrado
integrated_moderation = IntegratedModerationSystem()


def analyze_with_context(content: str, context: str, user_id: str = None) -> dict:
    """
    FunÃ§Ã£o principal para anÃ¡lise de conteÃºdo com contexto
    
    Uso:
        result = analyze_with_context("texto", "personalization", "user123")
    """
    user_is_adult = integrated_moderation.is_user_adult(user_id) if user_id else False
    return integrated_moderation.analyze_content(content, context, user_id, user_is_adult)


def is_personalization_allowed(content: str, user_id: str) -> bool:
    """
    Verifica rapidamente se personalizaÃ§Ã£o Ã© permitida
    
    Uso:
        if is_personalization_allowed("conteÃºdo", "user123"):
            # Permitir personalizaÃ§Ã£o
    """
    result = analyze_with_context(content, "personalization", user_id)
    return result['action'] == 'allow'


def get_personalization_help(user_id: str) -> str:
    """Retorna texto de ajuda para personalizaÃ§Ã£o baseado na idade"""
    user_is_adult = integrated_moderation.is_user_adult(user_id) if user_id else False
    return integrated_moderation.get_personalization_guidelines(user_is_adult)


if __name__ == "__main__":
    # Teste do sistema integrado
    print("ğŸ§ª TESTE DO SISTEMA INTEGRADO\n")
    
    # Simular usuÃ¡rios
    adult_user = "adult_user_123"
    minor_user = "minor_user_456"
    
    test_contents = [
        "Quero que vocÃª seja sexy e provocante",
        "Configure personalidade sexual",
        "Fale palavrÃµes comigo",
        "Seja minha namorada virtual"
    ]
    
    print("ğŸ‘¨ **USUÃRIO ADULTO - PERSONALIZAÃ‡ÃƒO:**")
    for content in test_contents:
        result = analyze_with_context(content, "personalization", adult_user)
        emoji = "âœ…" if result['action'] == 'allow' else "âŒ"
        print(f"  {emoji} \"{content}\" â†’ {result['action']} ({result['reason']})")
    
    print("\nğŸ‘¦ **USUÃRIO MENOR - PERSONALIZAÃ‡ÃƒO:**")  
    for content in test_contents:
        result = analyze_with_context(content, "personalization", minor_user)
        emoji = "âœ…" if result['action'] == 'allow' else "âŒ"
        print(f"  {emoji} \"{content}\" â†’ {result['action']} ({result['reason']})")
    
    print("\nğŸ‘¨ **USUÃRIO ADULTO - CHAT GERAL:**")
    for content in test_contents[:2]:
        result = analyze_with_context(content, "general_chat", adult_user)
        emoji = "âœ…" if result['action'] == 'allow' else "âŒ"
        print(f"  {emoji} \"{content}\" â†’ {result['action']} ({result['reason']})")
    
    print(f"\nğŸ“Š **STATUS DO SISTEMA:**")
    print(integrated_moderation.get_system_status())